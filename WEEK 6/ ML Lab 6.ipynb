{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f995f60",
   "metadata": {},
   "source": [
    "# Name.- Praveer Raj\n",
    "# Roll no. - 1\n",
    "# Reg no. - 230957002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb4c1e",
   "metadata": {},
   "source": [
    "# WEEK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca8eb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-2.1.0-cp39-cp39-win_amd64.whl (39 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
      "     -------------------------------------- 289.9/289.9 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5456d4",
   "metadata": {},
   "source": [
    "### EXER 1\n",
    "Download the \"Womens Clothing E-Commerce Reviews.zip\" file and answer the following:\n",
    "1. Preprocessing:\n",
    "a. Find any null values are present or not, If present remove those data.\n",
    "b. Remove the data that have less than 5 reviews.\n",
    "c. Clean the data and remove the special characters and replace the contractions with its \n",
    "expansion. Convert the uppercase character to lower case. Also, remove the \n",
    "punctuations.\n",
    "2. Separate the columns into dependent and independent variables (or features and \n",
    "labels). Then you split those variables into train and test sets (80:20).\n",
    "3. Apply the Naïve Bayes Classification Algorithm on Sentiment category to predict if \n",
    "item is recommended\n",
    "4. Tabulate accuracy in terms of precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f7f4338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maths\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maths\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.18      0.29       792\n",
      "           1       0.84      0.99      0.91      3464\n",
      "\n",
      "    accuracy                           0.84      4256\n",
      "   macro avg       0.85      0.58      0.60      4256\n",
      "weighted avg       0.85      0.84      0.80      4256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from contractions import fix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "file_path = r\"C:\\Users\\maths\\Desktop\\ML Week 6\\Womens Clothing E-Commerce Reviews.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = df.dropna(subset=['Review Text'])\n",
    "df = df.groupby('Clothing ID').filter(lambda x: len(x) >= 5)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = fix(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['Review Text'] = df['Review Text'].apply(clean_text)\n",
    "\n",
    "X = df['Review Text']\n",
    "y = df['Recommended IND']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177fbea",
   "metadata": {},
   "source": [
    "### EXER 2\n",
    "1. Data Preprocessing and Feature Engineering\n",
    "• Load the dataset and explore its structure.\n",
    "• Identify and handle missing values appropriately.\n",
    "• Perform feature selection by calculating correlation coefficients and removing \n",
    "highly correlated features.\n",
    "• Convert continuous variables into categorical bins where appropriate (e.g., \n",
    "discretizing age-based rates).\n",
    "• Apply dimensionality reduction techniques such as PCA to optimize feature \n",
    "space.\n",
    "• Create a binary target variable based on whether the 'Total.Rate' is above or below \n",
    "the third quartile, making classification more challenging.\n",
    "2. Split the dataset into training and testing sets with an 80-20 ratio.\n",
    "3. Implementing Naïve Bayes \n",
    "• Select the following features for classification:\n",
    "o Rates.Age.< 18\n",
    "o Rates.Age.18-45\n",
    "o Rates.Age.45-64\n",
    "o Rates.Age.> 64\n",
    "o Types.Lung.Race.White\n",
    "o Types.Lung.Race.Black\n",
    "o Types.Lung.Race.Hispanic\n",
    "• Train multiple Naïve Bayes models (GaussianNB, MultinomialNB, and \n",
    "BernoulliNB) using only the selected features.\n",
    "• Compare the models based on precision, recall, F1-score, and AUC-ROC curve.\n",
    "• Analyze the assumptions of each Naïve Bayes variant and determine which one \n",
    "fits the dataset best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2906c37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: Index(['State', 'Total.Rate', 'Total.Number', 'Total.Population',\n",
      "       'Rates.Age.< 18', 'Rates.Age.18-45', 'Rates.Age.45-64',\n",
      "       'Rates.Age.> 64', 'Rates.Age and Sex.Female.< 18',\n",
      "       'Rates.Age and Sex.Male.< 18', 'Rates.Age and Sex.Female.18 - 45',\n",
      "       'Rates.Age and Sex.Male.18 - 45', 'Rates.Age and Sex.Female.45 - 64',\n",
      "       'Rates.Age and Sex.Male.45 - 64', 'Rates.Age and Sex.Female.> 64',\n",
      "       'Rates.Age and Sex.Male.> 64', 'Rates.Race.White',\n",
      "       'Rates.Race.White non-Hispanic', 'Rates.Race.Black', 'Rates.Race.Asian',\n",
      "       'Rates.Race.Indigenous', 'Rates.Race and Sex.Female.White',\n",
      "       'Rates.Race and Sex.Female.White non-Hispanic',\n",
      "       'Rates.Race and Sex.Female.Black',\n",
      "       'Rates.Race and Sex.Female.Black non-Hispanic',\n",
      "       'Rates.Race and Sex.Female.Asian',\n",
      "       'Rates.Race and Sex.Female.Indigenous', 'Rates.Race and Sex.Male.White',\n",
      "       'Rates.Race and Sex.Male.White non-Hispanic',\n",
      "       'Rates.Race and Sex.Male.Black',\n",
      "       'Rates.Race and Sex.Male.Black non-Hispanic',\n",
      "       'Rates.Race and Sex.Male.Asian', 'Rates.Race and Sex.Male.Indigenous',\n",
      "       'Rates.Race.Hispanic', 'Rates.Race and Sex.Female.Hispanic',\n",
      "       'Rates.Race and Sex.Male.Hispanic', 'Types.Breast.Total',\n",
      "       'Types.Breast.Age.18 - 44', 'Types.Breast.Age.45 - 64',\n",
      "       'Types.Breast.Age.> 64', 'Types.Breast.Race.White',\n",
      "       'Types.Breast.Race.White non-Hispanic ', 'Types.Breast.Race.Black',\n",
      "       'Types.Breast.Race.Black non-Hispanic', 'Types.Breast.Race.Asian',\n",
      "       'Types.Breast.Race.Indigenous', 'Types.Breast.Race.Hispanic',\n",
      "       'Types.Colorectal.Total', 'Types.Colorectal.Age and Sex.Female.18 - 44',\n",
      "       'Types.Colorectal.Age and Sex.Male.18 - 44',\n",
      "       'Types.Colorectal.Age and Sex.Female.45 - 64',\n",
      "       'Types.Colorectal.Age and Sex.Male.45 - 64',\n",
      "       'Types.Colorectal.Age and Sex.Female.> 64',\n",
      "       'Types.Colorectal.Age and Sex.Male.> 64', 'Types.Colorectal.Race.White',\n",
      "       'Types.Colorectal.Race.White non-Hispanic',\n",
      "       'Types.Colorectal.Race.Black',\n",
      "       'Types.Colorectal.Race.Black non-Hispanic',\n",
      "       'Types.Colorectal.Race.Asian', 'Types.Colorectal.Race.Indigenous',\n",
      "       'Types.Colorectal.Race.Hispanic', 'Types.Lung.Total',\n",
      "       'Types.Lung.Age and Sex.Female.18 - 44',\n",
      "       'Types.Lung.Age and Sex.Male.18 - 44',\n",
      "       'Types.Lung.Age and Sex.Female.45 - 64',\n",
      "       'Types.Lung.Age and Sex.Male.45 - 64',\n",
      "       'Types.Lung.Age and Sex.Female.> 64',\n",
      "       'Types.Lung.Age and Sex.Male.> 64', 'Types.Lung.Race.White',\n",
      "       'Types.Lung.Race.White non-Hispanic', 'Types.Lung.Race.Black',\n",
      "       'Types.Lung.Race.Black non-Hispanic', 'Types.Lung.Race.Asian',\n",
      "       'Types.Lung.Race.Indigenous', 'Types.Lung.Race.Hispanic'],\n",
      "      dtype='object')\n",
      "Warning: 'Age' column not found in dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maths\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maths\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Missing features in dataset: ['Rates.Age.45-64', 'Types.Lung.Race.White', 'Types.Lung.Race.Black', 'Types.Lung.Race.Hispanic']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7456\\2300892459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mmissing_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Missing features in dataset: {missing_features}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Missing features in dataset: ['Rates.Age.45-64', 'Types.Lung.Race.White', 'Types.Lung.Race.Black', 'Types.Lung.Race.Hispanic']\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "file_path = r\"C:\\Users\\maths\\Desktop\\ML Week 6\\cancer.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Columns in dataset:\", df.columns)\n",
    "\n",
    "df = df.dropna()\n",
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "if 'Age' in df.columns:\n",
    "    age_bins = [0, 18, 45, 64, np.inf]\n",
    "    age_labels = ['<18', '18-45', '45-64', '>64']\n",
    "    df['Age Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n",
    "else:\n",
    "    print(\"Warning: 'Age' column not found in dataset.\")\n",
    "\n",
    "if 'Total.Rate' in df.columns:\n",
    "    y = (df['Total.Rate'] > df['Total.Rate'].quantile(0.75)).astype(int)\n",
    "else:\n",
    "    raise KeyError(\"Column 'Total.Rate' not found in dataset.\")\n",
    "\n",
    "selected_features = ['Rates.Age.< 18', 'Rates.Age.18-45', 'Rates.Age.45-64', 'Rates.Age.> 64', 'Types.Lung.Race.White', 'Types.Lung.Race.Black', 'Types.Lung.Race.Hispanic']\n",
    "missing_features = [feature for feature in selected_features if feature not in df.columns]\n",
    "if missing_features:\n",
    "    raise KeyError(f\"Missing features in dataset: {missing_features}\")\n",
    "\n",
    "X = df[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=min(5, X_train.shape[1]))\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'BernoulliNB': BernoulliNB()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"{name} Model:\")\n",
    "    print(f\"Precision: {report['1']['precision']}\")\n",
    "    print(f\"Recall: {report['1']['recall']}\")\n",
    "    print(f\"F1 Score: {report['1']['f1-score']}\")\n",
    "    print(f\"AUC-ROC: {auc}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd6335",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
